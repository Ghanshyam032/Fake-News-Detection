{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zeVE2TO3L7yk",
        "outputId": "eaa447b2-cd54-4ced-afdd-c5048e983b9a"
      },
      "outputs": [],
      "source": [
        "install.packages(\"syuzhet\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44ZurF4fN60U",
        "outputId": "28490731-aa98-4953-de59-d8a2649f7edc"
      },
      "outputs": [],
      "source": [
        "install.packages(\"caret\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WRT8QJXjInaC",
        "outputId": "f35bd94e-0880-4694-a5b1-6409ebdd754b"
      },
      "outputs": [],
      "source": [
        "## Importing packages\n",
        "library(tidyverse) # metapackage with lots of helpful functions\n",
        "library(tidytext) # tidy implimentation of NLP methods\n",
        "library(syuzhet)\n",
        "library(caret)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dKaR9gk8LHA-",
        "outputId": "936c06a9-39c8-4b3e-c0f9-e828248029e5"
      },
      "outputs": [],
      "source": [
        "# read in our data\n",
        "news <- read_csv(\"/content/fake.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jMskLfSWLKeP"
      },
      "outputs": [],
      "source": [
        "#bs and conspiracy news are also fake\n",
        "news$type<-gsub(\"bs\",\"fake\",news$type)\n",
        "news$type<-gsub(\"conspiracy\",\"fake\",news$type)\n",
        "#while others are real\n",
        "news$type<-gsub(\"bias\",\"real\",news$type)\n",
        "news$type<-gsub(\"satire\",\"real\",news$type)\n",
        "news$type<-gsub(\"hate\",\"real\",news$type)\n",
        "news$type<-gsub(\"junksci\",\"real\",news$type)\n",
        "news$type<-gsub(\"state\",\"real\",news$type)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 160
        },
        "id": "TykApbG-MO-l",
        "outputId": "3eae2a10-7b41-462c-f863-1a6b7ca452e3"
      },
      "outputs": [],
      "source": [
        "#Count of type of news that how many are fake and real\n",
        "news %>% group_by(type) %>% summarise(count=n())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zbh94DwDMQ1K"
      },
      "outputs": [],
      "source": [
        "#apply function for finding question marks and exclamations and adding into our dataframe\n",
        "news$exc <- sapply(news$text, function(x) length(unlist(strsplit(as.character(x), \"\\\\!+\")))) #count exclamation\n",
        "news$que <- sapply(news$text, function(x) length(unlist(strsplit(as.character(x), \"\\\\?+\")))) #count question marks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 160
        },
        "id": "1WGUdu1WMTLA",
        "outputId": "957ef200-1592-4420-b1d6-3da57cf6576f"
      },
      "outputs": [],
      "source": [
        "##Count of exclamations in fake and real news\n",
        "news %>% group_by(type) %>% summarise(exclamations=sum(exc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 160
        },
        "id": "-Opz6fvHMWag",
        "outputId": "43ce4c11-c0cc-4a6e-fe8b-5f7961276998"
      },
      "outputs": [],
      "source": [
        "#Count of question marks in fake and real news\n",
        "news %>% group_by(type) %>% summarise(QuestionMarks=sum(que))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "id": "NG-Lw3f8MZyr",
        "outputId": "7695e6e8-3835-49c1-8538-5b2c1fe82a6d"
      },
      "outputs": [],
      "source": [
        "#boxplot for exclamations in fake and real news\n",
        "boxplot(exc ~ type,news,ylim=c(0,20),ylab=\"\",col=c(\"red\",\"orange\"))\n",
        "#we can observe that fake news have more exclamations than real news"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "id": "KD8QmfVUMdUp",
        "outputId": "7ae5cb83-0b24-4d34-c404-95e44dbfa03d"
      },
      "outputs": [],
      "source": [
        "  #boxplot for question marks in fake and real news\n",
        "  boxplot(que ~ type,news,ylim=c(0,20),col=c(\"red\",\"orange\"))\n",
        "  #we can observe that fake news have more question marks than real"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xei5K3kNMj2G"
      },
      "outputs": [],
      "source": [
        "#function for finding words in each text\n",
        "terms<- function(fake, text_column, group_column){\n",
        "\n",
        "  group_column <- enquo(group_column)\n",
        "  text_column <- enquo(text_column)\n",
        "\n",
        "  # get the count of each word in each review\n",
        "  words <- news %>%\n",
        "    unnest_tokens(word, !!text_column) %>%\n",
        "    count(!!group_column, word) %>%\n",
        "    ungroup()\n",
        "\n",
        "  # get the number of words per text\n",
        "  #total_words <- words %>%\n",
        "    #group_by(!!group_column) %>%\n",
        "    #summarize(total = sum(n))\n",
        "\n",
        "  # combine the two dataframes we just made\n",
        "\n",
        "  return (words)\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lCk21DBEMoED"
      },
      "outputs": [],
      "source": [
        "#store all words per text in different data frame\n",
        "df<-terms(news,text,type)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "id": "sli-XoXcMpzV",
        "outputId": "37878037-eff6-49fd-83da-36f3f85ffe66"
      },
      "outputs": [],
      "source": [
        "#create boxplot for number of words of each type\n",
        "boxplot(n ~ type,df,log=\"y\",xlab=\"type\",ylab=\"number of words\",col=c(\"green\",\"pink\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "K5HWA0wkMsdD",
        "outputId": "3ce5ed2f-018e-4744-e5e7-da5b90cfe0cf"
      },
      "outputs": [],
      "source": [
        "#create sentiment table for text column\n",
        "sentiment<-get_nrc_sentiment(news$text)\n",
        "sentiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uhy-CWnbMuXF"
      },
      "outputs": [],
      "source": [
        "#taking only last two columns negative and positive for the analysis\n",
        "df1<-sentiment[c(9,10)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a2Kf7WH9Mvz7"
      },
      "outputs": [],
      "source": [
        "#function for normalization\n",
        "normalize <- function(x) {\n",
        "    return ((x - min(x)) / (max(x) - min(x)))\n",
        "  }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M2GScUxEMxCe"
      },
      "outputs": [],
      "source": [
        "#normalize negative and positive column for better analysis means the values will lie between 0 and 1\n",
        "df1$negative<-normalize(df1$negative)\n",
        "df1$positive<-normalize(df1$positive)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yjdYhCGtMyiU"
      },
      "outputs": [],
      "source": [
        "#Combine this with the news dataset\n",
        "news<-cbind(news,df1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pSv00ZFVM0Cw"
      },
      "outputs": [],
      "source": [
        "#finding standard deviations and median of negative and positive columns for each type of news\n",
        "neg_sd<-news %>% group_by(type) %>% summarise(neg_sd=sd(negative))\n",
        "pos_sd<-news %>% group_by(type) %>% summarise(pos_sd=sd(positive))\n",
        "neg_med<-news %>% group_by(type) %>% summarise(neg_med=median(negative))\n",
        "pos_med<-news %>% group_by(type) %>% summarise(pos_med=median(positive))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ZUri1nKOOWB"
      },
      "outputs": [],
      "source": [
        "#create dataframes for negative and positive standard deviations and median\n",
        "dfr2<-data.frame(neg_sd)\n",
        "dfr1<-data.frame(pos_sd)\n",
        "dfr3<-data.frame(neg_med)\n",
        "dfr4<-data.frame(pos_med)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "id": "PLq7SJujOW_l",
        "outputId": "cbc61ee6-a64c-4bbf-c634-485838e989c2"
      },
      "outputs": [],
      "source": [
        "t1<-merge(dfr1,dfr2)\n",
        "t2<-t(t1)\n",
        "t2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SD4AzM8F6dTe"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bsI5aR7d6dNW"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9TPXnneV6l_t",
        "outputId": "efe56b5b-b723-4d28-c7b3-4203a02c290d"
      },
      "outputs": [],
      "source": [
        "install.packages(\"caret\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CrVkTJYe8Qxj",
        "outputId": "8cd22207-66fa-458e-fd9d-b20d0de07542"
      },
      "outputs": [],
      "source": [
        "install.packages(\"tm\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_eUdFtXf8Vmk",
        "outputId": "62ac905d-2a2d-4d80-a7ef-54447c95c729"
      },
      "outputs": [],
      "source": [
        "install.packages(\"SnowballC\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XWPy8frG8Yzf",
        "outputId": "fc3237b4-8498-4ee4-8a34-de9ef2f4a6f1"
      },
      "outputs": [],
      "source": [
        "install.packages(\"e1071\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ibr9z1r_D55",
        "outputId": "1447e48f-be58-4b78-99ea-9611791a063c"
      },
      "outputs": [],
      "source": [
        "install.packages(\"caTools\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yqfv4wU46c62",
        "outputId": "37c0234d-d884-41d7-9b9b-39686c52da75"
      },
      "outputs": [],
      "source": [
        "library(tm)         # For text processing and document-term matrix\n",
        "library(SnowballC)  # For text stemming\n",
        "library(caTools)    # For data splitting\n",
        "library(caret)      # For model evaluation\n",
        "library(tidyverse)  # For data manipulation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EmowhJ6Z6ogo"
      },
      "outputs": [],
      "source": [
        "news_data <- read.csv(\"/content/fake_or_real_news.csv\", stringsAsFactors = FALSE)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ww8o40eH-2Ch"
      },
      "outputs": [],
      "source": [
        "corpus <- VCorpus(VectorSource(news_data$text))\n",
        "\n",
        "# Clean the text\n",
        "corpus <- tm_map(corpus, content_transformer(tolower))\n",
        "corpus <- tm_map(corpus, removeNumbers)\n",
        "corpus <- tm_map(corpus, removePunctuation)\n",
        "corpus <- tm_map(corpus, stripWhitespace)\n",
        "corpus <- tm_map(corpus, removeWords, stopwords(\"en\"))\n",
        "corpus <- tm_map(corpus, stemDocument)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0-oHREaV_SXo"
      },
      "outputs": [],
      "source": [
        "dtm <- DocumentTermMatrix(corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sB4Fb0d7_SRo"
      },
      "outputs": [],
      "source": [
        "news_data$label <- as.factor(ifelse(news_data$label == \"FAKE\", 0, 1))\n",
        "\n",
        "# Data splitting\n",
        "set.seed(123)\n",
        "split <- sample.split(news_data$label, SplitRatio = 0.75)\n",
        "train_indices <- which(split == TRUE)\n",
        "test_indices <- which(split == FALSE)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z4G-4qpS_SKx"
      },
      "outputs": [],
      "source": [
        "train_dtm <- dtm[train_indices,]\n",
        "test_dtm <- dtm[test_indices,]\n",
        "\n",
        "# Also split the labels accordingly\n",
        "train_labels <- news_data$label[train_indices]\n",
        "test_labels <- news_data$label[test_indices]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n0v8o8ge_Wpa"
      },
      "outputs": [],
      "source": [
        "library(e1071)\n",
        "model <- svm(as.matrix(train_dtm), train_labels, type = 'C-classification', kernel = 'linear')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fRH6_my0_ZPr"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
